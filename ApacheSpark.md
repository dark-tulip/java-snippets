Потоки бывают двух видов
- bounded
- unbounded (события постоянно; нет окончания потока)
где
- Apache Spark (ДВХ, витрины),
- Apache Flink (использует микробатчи и пострончно)

Apache Spark работает за счет микробатчинга, а обрабатывать разнородные данные за счет него не быввает всегда эффективным 
- Клик хаус принимает данные в построчном формате
- Изза чего пришлось менять его архитектуру Spark чтобы обрабатывать построчно

# DataFrame

- распределенная коллекция в виде именованных столбцов
- работает только со структурированными или полуструктурированными данными
- это помогает организовать информацию по столбцам как в реляционных БД
- ЖЕРТВУЕМ ТИПИЗАЦИЕЙ и поддержкой сложных типов

## Работает через Dynamic Allocation

- Добавляет исполнителей при нехватке ресурсов
- Удаляет неиспользуемые исполнители

### Условия для удаления:
- executorTimeout
### Условия для добавления:
- pending tasks (очередь задач превысила порог)

## Про Shuffle Service
- зачем нужен он?
- когда нужно сохранить shuffle данные удаленного shuffle service
- External Shuffle Service хранит данные отдельно от executor
1. Shuffle данные записываются на локальные диски, на которые смотрит ESS и executor
2. Когда исполнитель завершится, shuffle данные будут доступны через API ESS

# NULL PARTITION PROBLEM
- когда все записи с NULL ID отправляются в одну партицию - случается перекос данных
- Решение: использовать отрицательные идентификаторы
- `Data Skew` это когда происходит перекос данных в одной партиции
